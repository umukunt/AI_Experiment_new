{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in today's natural language processing (NLP) landscape, and their importance can be seen in several aspects:\n",
      "\n",
      "1. **Real-time Applications**: Fast language models enable real-time applications such as chatbots, virtual assistants, and language translation systems to respond quickly and efficiently. This is particularly important in customer-facing applications where delayed responses can lead to frustration and a negative user experience.\n",
      "2. **Low-Latency Requirements**: Many applications, such as voice assistants, require language models to process and respond to user input within a few hundred milliseconds. Fast language models can meet these low-latency requirements, ensuring a seamless user experience.\n",
      "3. **Scalability**: Fast language models can handle large volumes of data and user requests, making them essential for large-scale NLP applications such as language translation, sentiment analysis, and text summarization.\n",
      "4. **Energy Efficiency**: Fast language models can reduce the computational resources and energy required to process language tasks, making them more environmentally friendly and cost-effective.\n",
      "5. **Improved Accuracy**: Faster language models can process more data and perform more iterations, leading to improved accuracy and better performance in various NLP tasks.\n",
      "6. **Enhanced User Experience**: Fast language models can enable more interactive and engaging user experiences, such as conversational interfaces, voice-controlled devices, and augmented reality applications.\n",
      "7. **Competitive Advantage**: In today's fast-paced digital landscape, companies that can deploy fast and accurate language models can gain a competitive advantage over their rivals, improving customer satisfaction and driving business success.\n",
      "8. **Research and Development**: Fast language models can accelerate research and development in NLP, enabling researchers to explore new ideas, test hypotheses, and iterate on models more quickly.\n",
      "9. **Edge Computing**: Fast language models are essential for edge computing applications, where data is processed in real-time on devices such as smartphones, smart home devices, or autonomous vehicles.\n",
      "10. **Specialized Domains**: Fast language models can be fine-tuned for specialized domains such as healthcare, finance, or law, where timely and accurate language processing is critical.\n",
      "\n",
      "To achieve fast language models, researchers and developers employ various techniques, including:\n",
      "\n",
      "1. Model pruning and knowledge distillation\n",
      "2. Quantization and binarization\n",
      "3. Efficient neural network architectures\n",
      "4. Parallel processing and distributed computing\n",
      "5. GPU acceleration and specialized hardware\n",
      "6. Caching and memoization\n",
      "7. Approximation techniques and sampling methods\n",
      "\n",
      "By leveraging these techniques, fast language models can unlock new possibilities in NLP, enabling applications that were previously unimaginable.\n"
     ]
    }
   ],
   "source": [
    "api_key = os.environ.get('GROQ_API_KEY')\n",
    "client = Groq(api_key=api_key)\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Explain the importance of fast language models\"}\n",
    "    ],\n",
    "    model=\"llama3-70b-8192\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, client: Groq, system: str = \"\") -> None:\n",
    "        self.client = client\n",
    "        self.system = system\n",
    "        self.messages: list = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message=\"\"):\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama3-70b-8192\", messages=self.messages\n",
    "        )\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "get_city_population:\n",
    "e.g. get_city_population: Tokyo\n",
    "returns the population of the city\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the population of New York City plus 1 million?\n",
    "Thought: I need to find the population of New York City\n",
    "Action: get_city_population: New York City\n",
    "PAUSE \n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: 8,804,190\n",
    "\n",
    "Thought: I need to add 1 million to this number\n",
    "Action: calculate: 8804190 + 1000000\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this: \n",
    "\n",
    "Observation: 9,804,190\n",
    "\n",
    "If you have the answer, output it as the Answer.\n",
    "\n",
    "Answer: The population of New York City plus 1 million is 9,804,190.\n",
    "\n",
    "Now it's your turn:\n",
    "\"\"\"\n",
    "\n",
    "def calculate(operation: str) -> float:\n",
    "    return {\n",
    "            \"data\": [\n",
    "                {\n",
    "                    \"data\": eval(operation),\n",
    "                    \"response_type\": \"ResponseTypes.CODE.value\",\n",
    "                }\n",
    "            ],\n",
    "            \"tool_called\": \"ToolCalled.Trino_Data_Virtualization.value\"\n",
    "        }\n",
    "    \n",
    "\n",
    "def get_city_population(city: str) -> int:\n",
    "    match city.lower():\n",
    "        case \"tokyo\":\n",
    "            return 37_400_068\n",
    "        case \"delhi\":\n",
    "            return 31_399_000\n",
    "        case \"shanghai\":\n",
    "            return 27_058_000\n",
    "        case \"s√£o paulo\":\n",
    "            return 22_043_000\n",
    "        case \"mexico city\":\n",
    "            return 21_782_000\n",
    "        case \"cairo\":\n",
    "            return 20_901_000\n",
    "        case \"mumbai\":\n",
    "            return 20_411_000\n",
    "        case \"beijing\":\n",
    "            return 20_384_000\n",
    "        case \"dhaka\":\n",
    "            return 20_283_000\n",
    "        case \"osaka\":\n",
    "            return 19_165_000\n",
    "        case _:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neil_tyson = Agent(client=client, system=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to find the population of Tokyo City\n",
      "Action: get_city_population: Tokyo\n",
      "PAUSE\n",
      "Observation: 37400068\n",
      "Thought: I need to add 1 million to this number\n",
      "Action: calculate: 37400068 + 1000000\n",
      "PAUSE\n",
      "Observation: {'data': [{'data': 38400068, 'response_type': 'ResponseTypes.CODE.value'}], 'tool_called': 'ToolCalled.Trino_Data_Virtualization.value'}\n",
      "Thought: I have the result of the calculation, which is the population of Tokyo City plus 1 million \n",
      "\n",
      "Answer: The population of Tokyo City plus 1 million is 38400068.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def loop(max_iterations=10, query: str = \"\"):\n",
    "\n",
    "    agent = Agent(client=client, system=system_prompt)\n",
    "\n",
    "    tools = [\"calculate\", \"get_city_population\"]\n",
    "\n",
    "    next_prompt = query\n",
    "\n",
    "    i = 0\n",
    "  \n",
    "    while i < max_iterations:\n",
    "        i += 1\n",
    "        result = agent(next_prompt)\n",
    "        print(result)\n",
    "\n",
    "        if \"PAUSE\" in result and \"Action\" in result:\n",
    "            action = re.findall(r\"Action: ([a-z_]+): (.+)\", result, re.IGNORECASE)\n",
    "            chosen_tool = action[0][0]\n",
    "            arg = action[0][1]\n",
    "\n",
    "            if chosen_tool in tools:\n",
    "                result_tool = eval(f\"{chosen_tool}('{arg}')\")\n",
    "                next_prompt = f\"Observation: {result_tool}\"\n",
    "\n",
    "            else:\n",
    "                next_prompt = \"Observation: Tool not found\"\n",
    "\n",
    "            print(next_prompt)\n",
    "            continue\n",
    "\n",
    "        if \"Answer\" in result:\n",
    "            break\n",
    "\n",
    "\n",
    "loop(query=\"What is the population of tokyo City plus 1 million?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
